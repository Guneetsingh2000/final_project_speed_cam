{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_DIR: //Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb\n",
      "DATA_YAML  : //Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/data.yaml\n",
      "\n",
      "Exists?\n",
      "  DATASET_DIR: True\n",
      "  DATA_YAML  : True\n",
      "\n",
      "Dataset folder contents: ['README.roboflow.txt', 'valid', 'README.dataset.txt', '.DS_Store', 'test', 'data.yaml', 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_DIR = \"//Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb\"\n",
    "DATA_YAML   = os.path.join(DATASET_DIR, \"data.yaml\")\n",
    "\n",
    "print(\"DATASET_DIR:\", DATASET_DIR)\n",
    "print(\"DATA_YAML  :\", DATA_YAML)\n",
    "\n",
    "print(\"\\nExists?\")\n",
    "print(\"  DATASET_DIR:\", os.path.exists(DATASET_DIR))\n",
    "print(\"  DATA_YAML  :\", os.path.exists(DATA_YAML))\n",
    "\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    print(\"\\nDataset folder contents:\", os.listdir(DATASET_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training config:\n",
      "  DATA_YAML   : /Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/data.yaml\n",
      "  MODEL       : yolov8n.pt\n",
      "  PROJECT_DIR : /Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset\n",
      "  RUN_NAME    : car_detector_fast2\n",
      "New https://pypi.org/project/ultralytics/8.3.234 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.227 üöÄ Python-3.12.4 torch-2.8.0 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.2, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=car_detector_fast2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset/car_detector_fast2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 341.6¬±152.6 MB/s, size: 96.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/train/labels.cache... 1620 images, 159 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1620/1620 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/train/images/Sunny2_count18_leftlane_mp4-1084_jpg.rf.10d6e81572da89b62cf1f328f4d64a44.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/train/images/Sunny2_count18_leftlane_mp4-1084_jpg.rf.14f59b0190db3e9f0e723e1aaa7c431a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/train/images/Sunny2_count18_leftlane_mp4-1084_jpg.rf.ef2d5c68da8a2e979154478d75bc43ed.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 207.8¬±55.0 MB/s, size: 44.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/user/Desktop/final project lisance plate spped camara detection /data/car object detection project.v2i.yolov8-obb/valid/labels.cache... 752 images, 212 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 752/752 2.4Mit/s 0.0s0s\n",
      "Plotting labels to /Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset/car_detector_fast2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset/car_detector_fast2\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/5         0G      2.243      1.947      1.038         68        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 810/810 2.5it/s 5:18<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 8.3it/s 22.7s0.1ss\n",
      "                   all        752       5307      0.842      0.145      0.152     0.0816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/5         0G      1.839      1.445     0.9359         63        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 810/810 2.5it/s 5:21<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 8.7it/s 21.7s0.1ss\n",
      "                   all        752       5307      0.514      0.221      0.222      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        3/5         0G      1.696      1.176     0.9203         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 810/810 2.6it/s 5:09<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 9.4it/s 20.0s0.1ss\n",
      "                   all        752       5307      0.528      0.247      0.244      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        4/5         0G      1.567      1.046     0.9012         40        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 810/810 2.8it/s 4:51<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 7.9it/s 23.8s0.1ss\n",
      "                   all        752       5307      0.566      0.357      0.271      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        5/5         0G      1.527      1.077     0.8886         40        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 810/810 2.7it/s 4:59<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 7.0it/s 26.7s0.1ss\n",
      "                   all        752       5307      0.599      0.359       0.28      0.179\n",
      "\n",
      "5 epochs completed in 0.460 hours.\n",
      "Optimizer stripped from /Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset/car_detector_fast2/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset/car_detector_fast2/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset/car_detector_fast2/weights/best.pt...\n",
      "Ultralytics 8.3.227 üöÄ Python-3.12.4 torch-2.8.0 CPU (Apple M1)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 8.3it/s 22.7s<0.2s\n",
      "                   all        752       5307      0.599      0.359       0.28      0.179\n",
      "                   bus         14         14          1          0     0.0336     0.0259\n",
      "                   car        540       5189      0.432      0.518      0.473      0.293\n",
      "                 truck         47        104      0.367      0.558      0.334      0.218\n",
      "Speed: 0.3ms preprocess, 24.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/user/Desktop/final project lisance plate spped camara detection /runs_car_dataset/car_detector_fast2\u001b[0m\n",
      "\n",
      "‚è± Total training time: 28.1 minutes\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import time\n",
    "import os\n",
    "\n",
    "BASE_DIR     = \"/Users/user/Desktop/final project lisance plate spped camara detection \"\n",
    "DATASET_DIR  = os.path.join(BASE_DIR, \"data\", \"car object detection project.v2i.yolov8-obb\")\n",
    "DATA_YAML    = os.path.join(DATASET_DIR, \"data.yaml\")\n",
    "\n",
    "MODEL_WEIGHTS = \"yolov8n.pt\"\n",
    "PROJECT_DIR   = os.path.join(BASE_DIR, \"runs_car_dataset\")\n",
    "RUN_NAME      = \"car_detector_fast2\"   # new run name\n",
    "\n",
    "TOTAL_EPOCHS  = 5\n",
    "IMG_SIZE      = 320\n",
    "BATCH         = 2\n",
    "DATA_FRACTION = 0.2\n",
    "\n",
    "print(\"Training config:\")\n",
    "print(\"  DATA_YAML   :\", DATA_YAML)\n",
    "print(\"  MODEL       :\", MODEL_WEIGHTS)\n",
    "print(\"  PROJECT_DIR :\", PROJECT_DIR)\n",
    "print(\"  RUN_NAME    :\", RUN_NAME)\n",
    "\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(DATA_YAML):\n",
    "    raise FileNotFoundError(f\"data.yaml not found at: {DATA_YAML}\")\n",
    "\n",
    "model = YOLO(MODEL_WEIGHTS)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    epochs=TOTAL_EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH,\n",
    "    fraction=DATA_FRACTION,\n",
    "    project=PROJECT_DIR,\n",
    "    name=RUN_NAME,\n",
    "    patience=TOTAL_EPOCHS,\n",
    "    verbose=True,     # YOLO prints its own progress bar\n",
    "    device=\"cpu\",\n",
    "    workers=0,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\\n‚è± Total training time: {elapsed/60:.1f} minutes\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
